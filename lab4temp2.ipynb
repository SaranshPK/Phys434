{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Lab 4\n",
    "\n",
    "Saransh Kacharia\n",
    "<br>\n",
    "Nobember 1st, 2020"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem 1\n",
    "\n",
    "In this problem we are looking at the data from a gamma-ray satellite orbiting in low Earth orbit. It takes a reading of the number of particles detected every 100 milliseconds, and is in an approximately 90 minute orbit. While it is looking for gamma-ray bursts, virtually all of the particles detected are background cosmic rays."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "import h5py\n",
    "\n",
    "#this sets the size of the plot to something useful\n",
    "plt.rcParams[\"figure.figsize\"] = (20,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('gammaray_lab4.h5', 'r')\n",
    "data = np.array(hf.get('data'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(20, 15), sharex=True)\n",
    "\n",
    "n = 300000\n",
    "ax[0].plot((data[0,:n]-data[0,0])/60, data[1,:n])\n",
    "ax[0].set_title('Solar Phase vs Time', fontsize=20)\n",
    "ax[0].set_ylabel('Solar phase in degrees', fontsize=16)\n",
    "ax[1].plot((data[0,:n]-data[0,0])/60, data[2,:n])\n",
    "ax[1].set_title('Longitude vs Time', fontsize=20)\n",
    "ax[1].set_ylabel('Longitude in degrees', fontsize=16)\n",
    "ax[2].plot((data[0,:n]-data[0,0])/60, data[3,:n])\n",
    "ax[2].set_title('Particle Count vs Time', fontsize=20)\n",
    "ax[2].set_ylabel('Number of particles', fontsize=16)\n",
    "ax[2].set_xlabel('Time in minutes', fontsize=16)\n",
    "\n",
    "for axis in ax:\n",
    "    axis.set_xlim(0, 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "I plotted 300,000 rows of the data which shows data through 500 minutes. As we can see in the Longitude vs Time plot, the orbit is approximately 90 minutes. The Solar Phase vs Time plot has a period that is smaller than the Logitude vs Time plot because of the earths rotation.\n",
    "\n",
    "We also see a similar periodic shape in the background. This suggests that there is a background periodic signal which is contaminating the data. We  expect the background cosmic radiation to be a steady signal with no discernable patterns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(25, 10))\n",
    "\n",
    "h1 = ax[0].hist2d(data[2,:], data[3,:], bins=(360,30), density=True)\n",
    "ax[0].set_title(\"Particle Count Density vs Longitude\", fontsize = 20)\n",
    "ax[0].set_ylabel(\"Particle Count\", fontsize = 16)\n",
    "ax[0].set_xlabel(\"Longitude\", fontsize = 16)\n",
    "ax[0].set_ylim(0, 25)\n",
    "\n",
    "h2 = ax[1].hist2d(data[1,:], data[3,:], bins=(360,30), density=True)\n",
    "ax[1].set_title(\"Particle Count Density vs Solar Phase\", fontsize = 20)\n",
    "ax[1].set_ylabel(\"Particle Count\", fontsize = 16)\n",
    "ax[1].set_xlabel(\"Solar Phase\", fontsize = 16)\n",
    "ax[1].set_ylim(0, 25)\n",
    "fig.colorbar(h1[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "From the plots above we can conclude that the solar phase doesn't affect the background but the logitude does. As the longitude goes from 0 to 360 degrees we see the particle count decrease from -45 to 105 degrees before flattening out until 315 degrees, after which is jumps back up and cycles again.\n",
    "\n",
    "Cosmic rays should be constant and independent of longitude. This confirms our theory that there is a periodic signal contamination in the background that depends on longitude."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We know that the number of cosmic rays is a finite number so we can find a Poisson distribution for each degree of Longitude. To do that we can find a mean for each longitude and then calculate a Poisson distribution with that mean."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(data[3][i::54000]) for i in range(54000)]\n",
    "longe = [data[2][i] for i in range(54000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.tick_params(labelsize = 16)\n",
    "plt.title(\"Particle Count Mean vs Longitude\", fontsize = 20)\n",
    "plt.ylabel(\"Particle Count Mean\", fontsize = 16)\n",
    "plt.xlabel(\"Longitude\", fontsize = 16)\n",
    "plt.ylim(0, 25)\n",
    "plt.xlim(0, 360)\n",
    "plt.scatter(longe[::100], means[::100])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "This is a plot of the mean of the particle count at each Longitude. As expected, it follows the brightest region of the 2D Histogram.\n",
    "\n",
    "The PDF with time dependence can be modeled with a function that calculates the Longitude from the time and then determines the PMF from the Poisson distribution at that Longitude."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x, time):\n",
    "    longeVal = data[2][time*10]\n",
    "    idx = (np.abs(longe - longeVal)).argmin()\n",
    "    return stats.poisson.pmf(x, means[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareModel(time):\n",
    "    x = np.arange(0,26)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.tick_params(labelsize = 16)\n",
    "    plt.title(f\"Particle Count at {time} seconds\", fontsize = 20)\n",
    "    plt.ylabel(\"Probability Density\", fontsize = 16)\n",
    "    plt.xlabel(\"Particle Count\", fontsize = 16)\n",
    "    plt.step(x, pdf(x, time))\n",
    "\n",
    "    longeVal = data[2][time*10]\n",
    "    \n",
    "    normFactor = 1/sum(h1[0][int(longeVal)])\n",
    "    x1 = h1[2][1:]\n",
    "    plt.step(x1, h1[0][int(longeVal),:]*normFactor)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "compareModel(0)\n",
    "compareModel(1000)\n",
    "compareModel(2000)\n",
    "compareModel(3000)\n",
    "compareModel(4000)\n",
    "compareModel(5000)"
   ]
  },
  {
   "source": [
    "Comparing our model to the data, we can see that our model performs well. The real data distribution is shifted slightly to the right because our model calculate the distribution more finely. When comparing it with real data we determine the Logitude at that given time then we average our data over 1 degree. This results in a slight shift to the right because we are including a greater range of times.\n",
    "\n",
    "We can now find the 5-sigma threshold for different time/longitude values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma5(time):\n",
    "    longeVal = data[2][time*10]\n",
    "    idx = (np.abs(longe - longeVal)).argmin()\n",
    "    sigma = 1 - stats.norm.cdf(5)\n",
    "    requiredParticles = stats.poisson.ppf(1-sigma, mu = means[idx])\n",
    "    print(f'Measurement needed for 5-sigma confidence at {time:4d} seconds: {requiredParticles}')\n",
    "\n",
    "sigma5(0)\n",
    "sigma5(4000)\n",
    "sigma5(4060)"
   ]
  },
  {
   "source": [
    "As we can see, the sigma value changes for different times/longitudes. It ranges from 21 to 32 depending on the time/longitude.\n",
    "\n",
    "This dependance of the particle count on longitude comes from the South Atlantic Anomaly. In this region we measure a greater number of cosmic rays."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem 2\n",
    "\n",
    "In this problem we are going to look at a stack of telescope images. From these images we will determine the faintest stars."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('images.h5', 'r')\n",
    "stack = xr.DataArray(hf.get('imagestack')[:,:,:], coords=[np.arange(200), np.arange(200),np.arange(10)], dims=['x', 'y', 'image']).transpose('image','x','y')\n",
    "stack.plot(center=False, col='image', col_wrap=2, size=5)\n",
    "hf.close()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "From these images, it is difficult to locate the faintest stars. Something we can do is to calculate a PDF of the pixel brightness of all the images, and because a stars brightness is independent of time, that star should be there for all of the images. Due to this we can sum the brightness for each pixel between the images then find the PDF. There is some contamination but when summing all the images the contamination will be washed out."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_sum = sum(stack)\n",
    "stack_sum.plot.hist(bins=2000, density=True, size=5)\n",
    "plt.title(\"Probability for Brightness of Pixel\")\n",
    "plt.xlim([-10,50])\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Brightness\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We can see that the background is a normal distribution and the stars which are brighter are outside the background distribution. We can determine the mean and standard deviation of the background distribution to count the number of stars that are any sigma threshold brighter than the background.\n",
    "\n",
    "We can remove any data points that are greater that 8 brightness to calculate the mean and standard deviation of the background."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_sum_trimmed = stack_sum.where(stack_sum < 8)\n",
    "mean = stack_sum_trimmed.mean().values\n",
    "std = stack_sum_trimmed.std().values\n",
    "print(f\"Mean: {mean:.3f}\")\n",
    "print(f\"Standard Deviation: {std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_sum_trimmed.plot.hist(bins=100, density=True, size=5)\n",
    "x = np.linspace(-7,7,1000)\n",
    "pdf = stats.norm.pdf(x, loc=mean, scale=std)\n",
    "plt.plot(x, pdf)\n",
    "plt.title(\\\"Probability for Brightness of Pixel\\\")\n",
    "plt.xlim([-10,10])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We find that the background brightness has a mean of -0.002 and a standard deviation of 1.776. We can see from the plot that a normal distribution with these parameters fits the background data well. Now we can find faint stars by counting the number of stars that are brighter with sigma values greater than a certain threshold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars(sigma):\n",
    "    prob = 1 - stats.norm.cdf(sigma)\n",
    "    requiredBrightness = stats.norm.ppf(1 - prob, loc=mean, scale=std)\n",
    "    print(f\"Brightness of {requiredBrightness:.2f} or more is {sigma} sigma\")\n",
    "    n = stack_sum.where(stack_sum > requiredBrightness).count().values\n",
    "    print(f\"There are {n} pixels bright enough to be stars with {sigma} sigma certainty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars(5)\n",
    "print(\"\")\n",
    "stars(7)"
   ]
  },
  {
   "source": [
    "We can conclude with 5 sigma certainty that there are 125 stars. We can conclude with 7 sigma certainty that there are 121 stars. That means there are 4 stars that are the faintest stars with brightnesses between 8.88 and 12.43 when all the images are summed.\n",
    "\n",
    "My partner and I had a different PDF because we were looking for different things. To look for a transient, the PDF that would have been used in that case would be to average of all the images and then subtracting each image from the average. After which you could find the probability of seeing something that isn't in any of the other images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}